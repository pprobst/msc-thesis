% -*- mode: latex; coding: utf-8 -*-
\input{blocksworld.tex}

%\documentclass{gkibeamer}
\documentclass{beamer}

\usepackage{tikz}
\usepackage{ifthen}
\usepackage{stmaryrd}
\usepackage[T1]{fontenc}
\usepackage[brazil]{babel}
\usepackage[utf8]{inputenc}
%\usetheme{Inf}
%\usetheme{}
\usecolortheme{rose}

%\setbeamertemplate{footline}[frame number]
\setbeamertemplate{footline}{%
  \begin{beamercolorbox}[wd=\paperwidth,ht=2.25ex,dp=2ex]{author in head/foot}%
    \usebeamerfont{author in head/foot}%
    \hfill 
    \hspace*{1em} \insertframenumber\hspace*{1em} % Only display current page number
  \end{beamercolorbox}%
}

\setbeamertemplate{navigation symbols}{}

\title[Discovering and Learning Preferred Operators]{Discovering and Learning Preferred Operators for Classical Planning with Neural Networks}
\author{Pedro Probst Minini}

%\institute{Federal University of Rio Grande do Sul\\Institute of Informatics\\Department of Theoretical Informatics}
%\subject{AI}

\input{macros}

% #############################################################################################################
%
%% Needed for "Content of this Course" slide in most chapters:
\usetikzlibrary{positioning, calc, decorations.pathreplacing, arrows, arrows.meta, patterns, automata}
\usepackage[outline]{contour} % glow around text
\contourlength{1.4pt}
\tikzset{>=latex} % for LaTeX arrow head
\colorlet{myred}{red!80!black}
\colorlet{myblue}{blue!80!black}
\colorlet{mygreen}{green!60!black}
\colorlet{myorange}{orange!70!red!60!black}
\colorlet{mydarkred}{red!30!black}
\colorlet{mydarkblue}{blue!40!black}
\colorlet{mydarkgreen}{green!30!black}
\tikzset{ % node styles, numbered for easy mapping with \nstyle
  my nodes/.style={circle,inner sep=0,minimum size=8mm},
  input/.style={my nodes,draw=mygreen,fill=mygreen!20,text=green!50!black},
  hidden/.style={my nodes,draw=violet,fill=violet!20,text=violet},
  output/.style={my nodes,draw=myred!60!black,fill=myred!20,text=red!60!black},
  my text/.style={text=#1,text width=1cm,align=center}
}

\usepackage[linesnumbered, ruled, vlined]{algorithm2e}
\usepackage{mathtools}
\usepackage{booktabs}
\usepackage{comment}
\usepackage{multicol}
%\usepackage{natbib}
\usepackage[citestyle=authoryear,maxnames=10,maxcitenames=1,giveninits=true,backend=biber,uniquelist=false]{biblatex}
\usepackage[utf8]{inputenc}
\usepackage[textsize=tiny,colorinlistoftodos,prependcaption]{todonotes}
\addbibresource{biblio.bib}

\newcommand{\pp}[2][noinline]{\todo[color=purple!50,linecolor={purple!100},#1,fancyline,author=Pedro]{#2}}
\newcommand{\ppi}[2][inline]{\todo[color=purple!50,linecolor={purple!100},#1,fancyline,author=Pedro]{#2}}

% #####################
\AtBeginSubsection[]
{
\begin{frame}[noframenumbering]
    %\frametitle{\n}
    \begin{beamercolorbox}[sep=8pt,center,shadow=true,rounded=true]{title}
      \usebeamerfont{title}\insertsectionhead\par%
    \end{beamercolorbox}
    \tableofcontents[currentsection,currentsubsection]
\end{frame}
}

\AtBeginSection[]{
  \begin{frame}
    \setbeamercolor{section title}{fg=beamer@blendedblue,bg=structure}
    \usebeamercolor[fg]{section title}
    \centering
    \Huge\insertsectionhead
  \end{frame}
}
% #####################

\addbibresource{biblio.bib}

% #############################################################################################################

%\subtitle{Some title}
%\date{}
%\begin{document}

%\begin{frame}{Outline}
%\tableofcontents
%\end{frame}

% Define the title with \title[short title]{long title}
% Short title is optional
\title[Discovering and Learning Preferred Operators]
      {Discovering and Learning Preferred Operators for Classical Planning with Neural Networks}

% Optional subtitle
%\subtitle{Defesa de Mestrado}

\date{Julho de 2023}

% Author information
\author{Pedro Probst Minini}
\institute{Instituto de Informática --- UFRGS}

\begin{document}

% Command to create title page (INF)
%\InfTitlePage

\begin{frame}[plain]
  \titlepage
\end{frame}

\begin{frame}{Outline}
  \frametitle{Agenda}
  \tableofcontents
\end{frame}

\section{Problema}
\begin{frame}{O que queremos fazer?}
\begin{itemize}
  \item Queremos aprender \alert{ações} que tornem a busca mais \alert{eficiente} durante a resolução de uma tarefa de planejamento.
  \pause
  \item Abordagens existentes são baseadas em lógica (e.g. operadores preferidos do FF).
  \pause
  \item Vários métodos para o aprendizado de funções heurísticas usando redes neurais.
  \begin{itemize}
    \item Mas nada sobre aprender operadores preferidos.
  \end{itemize}
  \pause
  \item Propomos um método para gerar amostras de estados, onde \alert{cada estado tem um conjunto de operadores preferidos}.
  \pause
  \item Usamos esses conjuntos de amostras gerados para \alert{treinar redes neurais} que, durante a busca, escolhem operadores preferidos para o estado atual.
\end{itemize}
\end{frame}

\section{Introdução}

\subsection{Planejamento}
\begin{frame}{Planejamento Clássico}
\emph{Planejamento} tem o objetivo de encontrar uma \alert{sequência de ações} a partir de um \alert{estado inicial} que satisfaça as \alert{condições objetivo}.
    \begin{exampleblock}{\strut Exemplo: Planejamento Clássico}
      \hilite{ambiente}
      \begin{itemize}
      \item \alert{estático} vs.\ \grey{dinâmico}
        \pause
      \item \alert{determinístico} vs.\ \grey{não determinístico}
        vs.\ \grey{estocástico}
        \pause
      \item \alert{observável}
        vs.\ \grey{parcialmente observável}
        vs.\ \grey{não observável}
        \pause
      \item \alert{discreto} vs.\ \grey{contínuo}
        \pause
      \item \alert{agente único} vs.\ \grey{agentes multiplos}
      \end{itemize}

      \pause
      \hilite{método de resolução}
      \begin{itemize}
      \item \grey{específico por problema} vs.\ \alert{geral} vs.\ \orange{aprendizado}
      \end{itemize}
    \end{exampleblock}
% ppi{Then briefly talk about non-deterministic planning.}
% Classical Planning is an example of a "model".
\end{frame}

\begin{frame}{STRIPS}
  \begin{definition}[Um problema de planejamento em STRIPS]
    $\Pi = \langle F, O, s_{0}, s^{*}\rangle$ onde
    \begin{itemize}
        \item $F$ é um conjunto de variáveis booleanas (\alert{fatos ou proposições}),
        \item $O$ é um conjunto de \alert{operadores} ou ações sobre $F$, onde $\langle pre(o), add(o), del(o) \rangle \subseteq F$,
        \item $s_{0} \subseteq F$ é o conjunto de fatos que representa o \alert{estado inicial}, e
        \item $s^{*} \subseteq F$ é o conjunto de fatos que devem ser satisfeitos (``\alert{gol}'').
    \end{itemize}
   \pause
    As ações $A(s)$ são \alert{aplicáveis} em $s$ se elas satisfizerem $pre(o)$.

    Avançamos de um estado $s$ com o operador $o$ definindo as proposições em $add(o)$ como \alert{verdadeiras} e em $del(o)$ como \alert{falsas}.
    \pause

    Por fim, $\pi = o_{1}, o_{2},\ldots, o_{n}$ é chamado de \alert{plano} para $\Pi$, em que $o_{i}$ é um operador aplicável.
\end{definition}
%Planning tasks are usually formally described in PDDL files, following a Lisp-like structure.
\end{frame}

\begin{frame}{Example: Blocksworld} 
\begin{figure}
    \centering
    \includegraphics[width=7cm]{img/blocksworld1.png}
    \caption{Uma tarefa de planejamento do domínio Blocks World.}
\end{figure}
\end{frame}

\begin{frame}{Exemplo: Blocksworld}
% This is from Malte Helmert's slides, slightly modified.
    \begin{exampleblock}{\strut Exemplo: Blocks World}
      \hilite{$\Pi = \langle F, O, s_{0}, s^{*}\rangle$}
      \begin{itemize}
      \item $F$ = \{on(a,b), on(a,c), on(b,a), on(b,c), on(c,a), on(c,b), on-table(a), on-table(b), on-table(c), clear(a), clear(b), clear(c)\}

       \item $O$ = \{move(a,b,c), move(a,c,b), move(b,a,c), move(b,c,a), move(c,a,b), move(c,b,a), to-table(a,b), to-table(a,c), to-table(b,a), to-table(b,c), to-table(c,a), to-table(c,b), from-table(a,b), from-table(a,c), from-table(b,a), from-table(b,c), from-table(c,a), from-table(c,b)\}

        \item $s_{0}$ = \{on(c,a), on-table(a), on-table(b), clear(c), clear(b)\}

         \item $s^{*}$ = \{on(a,b), on(b,c)\}
      \end{itemize}
    \end{exampleblock}
\end{frame}

\begin{frame}{Exemplo: Blocks World}
    \begin{exampleblock}{\strut Exemmplo: Blocks World}
      \begin{itemize}
      \item \emph{move}: move a block from one block to another.
      \begin{itemize}
        \item Pre(move(a,b,c)) = \{on(a,b), clear(a), clear(c)\}
        \item Add(move(a,b,c)) = \{on(a,c), clear(b)\}
        \item Del(move(a,b,c)) = \{on(a,b), clear(c)\}
        \item Com base no estado inicial, essa ação é aplicável? % Não, ela não satisfaz as condições prévias.
      \end{itemize}
      \item \emph{to-table}: mover um bloco de um bloco para a mesa.
      \item \emph{from-table}: mover um bloco de um bloco para a mesa.
      \end{itemize}
    \end{exampleblock}
\end{frame}

\begin{frame}{Espaço de estados do Blocks World com 3 blocos}
  \begin{center}
    \begin{pgfpicture}{-39mm}{-32.4mm}{39mm}{32.4mm}
      \pgfnodebox{RsGsB}[virtual]{\pgfpolar{0}{0cm}}{\RsGsB}{2pt}{2pt}

      \pgfnodebox{RGsB}[virtual]{\pgfpolar{0}{16mm}}{\RGsB}{2pt}{2pt}
      \pgfnodebox{RBsG}[virtual]{\pgfpolar{60}{16mm}}{\RBsG}{2pt}{2pt}
      \pgfnodebox{BRsG}[virtual]{\pgfpolar{120}{16mm}}{\BRsG}{2pt}{2pt}
      \pgfnodebox{RsBG}[virtual]{\pgfpolar{180}{16mm}}{\RsBG}{2pt}{2pt}
      \pgfnodebox{RsGB}[virtual]{\pgfpolar{240}{16mm}}{\RsGB}{2pt}{2pt}
      \pgfnodebox{GRsB}[virtual]{\pgfpolar{300}{16mm}}{\GRsB}{2pt}{2pt}

      \pgfnodebox{BRG}[virtual]{\pgfpolar{0}{32mm}}{\BRG}{2pt}{2pt}
      \pgfnodebox{GRB}[virtual]{\pgfpolar{50}{32mm}}{\GRB}{2pt}{2pt}
      \pgfnodebox{GBR}[virtual]{\pgfpolar{130}{32mm}}{\GBR}{2pt}{2pt}
      \pgfnodebox{RBG}[virtual]{\pgfpolar{180}{32mm}}{\RBG}{2pt}{2pt}
      \pgfnodebox{RGB}[virtual]{\pgfpolar{230}{32mm}}{\RGB}{2pt}{2pt}
      \pgfnodebox{BGR}[virtual]{\pgfpolar{310}{32mm}}{\BGR}{2pt}{2pt}

      \pgfsetendarrow{\pgfarrowtriangle{5pt}}
      \pgfsetstartarrow{\pgfarrowtriangle{5pt}}

      \pgfnodeconnline{RsGsB}{RGsB}
      \pgfnodeconnline{RsGsB}{RBsG}
      \pgfnodeconnline{RsGsB}{BRsG}
      \pgfnodeconnline{RsGsB}{RsBG}
      \pgfnodeconnline{RsGsB}{RsGB}
      \pgfnodeconnline{RsGsB}{GRsB}

      \pgfnodeconnline{RGsB}{BRG}
      \pgfnodeconnline{RBsG}{GRB}
      \pgfnodeconnline{BRsG}{GBR}
      \pgfnodeconnline{RsBG}{RBG}
      \pgfnodeconnline{RsGB}{RGB}
      \pgfnodeconnline{GRsB}{BGR}

      \pgfnodeconnline{RGsB}{RBsG}
      \pgfnodeconnline{BRsG}{RsBG}
      \pgfnodeconnline{RsGB}{GRsB}
    \end{pgfpicture}
  \end{center}
\end{frame}

\begin{frame}{\sas}
\begin{itemize}
\item \sas é similar a STRIPS, mas variáveis têm domínios finitos, não sendo necessariamente binárias.
  \item O estado inicial $s_{0}$ é tipicamente um \alert{estado completo}, i.e., todas as variáveis estão definidas.
  \item O gol $s^{*}$ é definido \alert{parcialmente}, com certas variáveis indefinidas ($\bot$).
\end{itemize}
\end{frame}

\subsection{Busca Heurística}
\begin{frame}{O que é busca heurística?}
\begin{itemize}
  \item Planejadores tipicamente buscam satisfazer o gol \alert{priorizando} estados no espaço de estados com \alert{menor função heurística}.
  \pause
  \item Um estado $s$ tem uma função heurística $h(s)$, dado por uma função heurística $h$, que estima o \alert{custo de atingir o gol $s^{*}$} a partir de $s$.
  \pause
  \item Algoritmos ``best-first search'', e.g., greedy best-first serach (GBFS), \astar.
\end{itemize}
\end{frame}

\subsection{Operadores Preferidos}
\begin{frame}{O que são operadores preferidos?}
\begin{itemize}
\item \alert{Operadores} considerados \alert{promissores} ``por alguma razão''.
    \pause
  \begin{itemize}
  \item A definição não é fechada, mas tipicamente isso quer dizer ``operadores que levam a algum estado mais provável de satisfazer o gol''. % Helmert e eu.
  \end{itemize}
  \pause
\item Usados em conjunto com funções heurísticas.
  \begin{itemize}
  \item Sozinhos, são equivalentes a políticas (policies).
  \end{itemize}
\pause
\item No Fast Downward: usados em esquema ``\alert{dual-queue}''.
  \begin{itemize}
  \item Uma fila para todos os estados, outra para \alert{estados gerados exclusivamente via POs}.
  \item Expansão alternada, ou não (\alert{boosting}).
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Operadores preferidos do FF}
\end{frame}

\subsection{Aprendizado de Funções Heurísticas}
\begin{frame}{Como aprender funções heurísticas?}
\begin{itemize}
  \item Abordagem que depende \alert{muito} da lógica do domínio.
    \begin{itemize}
      \item Arquitetura da rede reflete a lógica do domínio.
    \end{itemize}
  \pause
  \item Abordagem que depende \alert{pouco} da lógica do domínio.
    \begin{itemize}
      \item Apenas usa lógica do domínio para extrair mutexes e operadores aplicáveis durante a amostragem.
      \item Arquitetura da rede neural tende a ser simples (feedforward NN)
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Como aprender funções heurísticas?}
Em particular, este trabalho segue a segunda abordagem para o aprendizado de funções heurísticas e operadores preferidos.
\begin{itemize}
  \item Aprendizado supervisionado.
  \item Uso de lógica do domínio apenas para a derivação de mutexes e operadores aplicáveis durante o processo de amostragem.
  \item Estratégia de \cite{Bettker.etal/2022}.
\end{itemize}
\end{frame}


\section{Abordagem Proposta}
\begin{frame}{Como aprender operadores preferidos?}

\end{frame}

\subsection{Operadores Preferidos Ideais}
\begin{frame}{Operadores preferidos ideais}
\end{frame}

\subsection{Operadores Preferidos Descobertos}
\begin{frame}{Operadores preferidos descobertos}
\end{frame}

\subsection{Gerando Amostras com \bfsrs}
\begin{frame}{Gerando amostras com \bfsrs}
\end{frame}

\section{Experimentos}
\subsection{Preliminares}
\begin{frame}{Configuração}
\begin{itemize}
  \item Geração de amostras
  \begin{itemize}
    \item Neural Fast Downward~(\cite{Ferber.etal/2020a}).
  \end{itemize}
  \item Redes neurais
  \begin{itemize}
    \item PyTorch 1.9.0~(\cite{Paszke/2019}).
  \end{itemize}
  \item Máquinas Ubuntu~$20.04$~LTS~GNU/Linux
  \begin{itemize}
    \item AMD~Ryzen~$9$~$3900$X $12$-core ($4.2$~GHz).
    \item Limites de $4$~GB RAM e um núcleo por processo.
  \end{itemize}
\end{itemize}
\end{frame}


\begin{frame}{Tarefas de benchmark}
\input{tables/tasks_info.tex}
\end{frame}

\begin{frame}{Geração de samples}
\begin{itemize}
  \item Amostragem usando \alert{\bfsrs} a partir do gol de uma tarefa de cada domínio.
  \pause
  \item Geramos $N$ samples, onde $N$ é a porcentagem do tamanho do espaço de estados (FSP) de cada tarefa.
    \begin{itemize}
      \item e.g. em Blocks, $5\,\%$ é $\lfloor 65990 \times 0.05 \rceil = 3300$ amostras.
    \end{itemize}
  \pause
  \item Para cada tarefa, geramos \alert{$5$} conjuntos de amostras (\emph{seeds}).
  \pause
  \item Formato de cada amostra: $(h(s), \mathcal{F}(s), O_{pref} \subseteq O)$.
    \begin{itemize}
      \item $15;000000011110\ldots000100000001;27,26$
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Treino}
\begin{itemize}
  \item Duas redes treinadas separadamente: \alert{regressão} com MSE para funções heurísticas, \alert{classificação} com BCE para POs.
  \pause
  \item $5$ net seeds ($= 5~\text{net seeds} \times 5~\text{sample seeds} = 25~\text{seeds}~\text{por tarefa}$).
  \pause
  \item Treino até \alert{early-stop} (treino mais longo durou~$2$h).
\end{itemize}

\pause
\begin{figure}[tb]
\caption[]{Tensor de saída de exmplo, com dois POs como ``target''.}
\centering
\begin{tikzpicture}[node distance=1cm]
  % Operators
  %\foreach \x in {1,...,10}
  %  \node[draw, minimum width=1cm, minimum height=0.5cm] (op\x) at (\x,0) {$o_{\x}$};
  \foreach \x in {1,...,10}{
    \ifnum\x=2
      \node[draw, minimum width=1cm, minimum height=0.5cm, fill=mygreen!30] (op\x) at (\x,0) {$o_{\x}$};
    \else
      \ifnum\x=5
        \node[draw, minimum width=1cm, minimum height=0.5cm, fill=mygreen!30] (op\x) at (\x,0) {$o_{\x}$};
      \else
        \node[draw, minimum width=1cm, minimum height=0.5cm] (op\x) at (\x,0) {$o_{\x}$};
      \fi
    \fi
  }
  % Sampled state
  \node[draw, minimum width=1cm, minimum height=0.5cm, above=of op2] (s) {$s$};

  % Arrows
  \draw[->] (s) -- (op2);
  \draw[->] (s) -- (op5);
\end{tikzpicture}
\label{fig:po-tensor}
\end{figure}

\end{frame}

\begin{frame}{Teste (aka busca)}
\begin{itemize}
  \item Para cada tarefa original, \alert{$50$ tarefas de teste} geradas via passeio aleatório a partir do estado inicial.
  \pause
  \item Buscas utilizando o GBFS implementado no Fast Downward, com limite de \alert{$5$ minutos} por tarefa.
  \pause
  \item Todas as tarefas têm cobertura total mesmo com busca cega, então o parâmetro de comparação escolhido é o \alert{número de estados expandidos}.
\end{itemize}
\end{frame}

\begin{frame}{Legenda}
\begin{multicols}{2}
\begin{itemize}
  \item \hstar
    \begin{itemize}
      \item heurística perfeita
    \end{itemize}
  \item \hnn
    \begin{itemize}
      \item heurística aprendida
    \end{itemize}
  \item \postartable
    \begin{itemize}
      \item POs perfeitos (oráculo)
    \end{itemize}
  \item \postar
    \begin{itemize}
      \item POs ideais (aprendidos)
    \end{itemize}
  \item \pogstar
    \begin{itemize}
      \item POs descobertos (\hstar)
    \end{itemize}
  \item \alert{\pog}
    \begin{itemize}
      \item POs descobertos
    \end{itemize}

\end{itemize}
\end{multicols}
\end{frame}

\subsection{Aprendendo Operadores Preferidos}
\begin{frame}{Conseguimos aprender algo?}
\input{tables/learning_perfect_pos.tex}
\end{frame}

\begin{frame}{E treinando com mais amostras?}
\input{tables/learning_discovered_pos.tex}
\end{frame}

\subsection{Comparando \bfsrs e \bfsrw}
\begin{frame}{\bfsrs vs. \bfsrw}
\input{tables/comparison_sample.tex}
\end{frame}

\subsection{Operadores Preferidos com Funções Heurísticas Lógicas}
\begin{frame}{POs com heurísticas lógicas}
  \input{tables/logic_heuristics_1pct.tex}
\end{frame}


\section{Conclusão}
\begin{frame}{Conclusão}
\begin{itemize}
  \item Abordagens ``learning-based'' têm considerável \alert{potencial} para superar abordagens ``logic-based''.
  \pause
  \item POs aprendidos \pog têm \alert{menos expansões} do que \poff nas tarefas de teste.
  \pause
    \begin{itemize}
      \item Isso é mais evidente quando a heurística usada é menos informada.
    \end{itemize}
  \pause
  \item Dado um conjunto com número de amostras representando uma porcentagem do espaço de estados, POs aprendidos \alert{generalizam bem} para o espaço de estados completo de uma tarefa.
\end{itemize}
\end{frame}

\begin{frame}{Trabalhos futuros}
\begin{itemize}
  \item Nossa abordagem é muito boa, mas pode melhorar.
  \pause
  \item Treinar sobre $5\,\%$ do espaço de estados para superar \poff ainda exige um número considerável de amostras. Aprender POs é uma tarefa \alert{difícil}.
  \begin{itemize}
    \pause
    \item Além disso, algumas tarefas de planejamento têm \alert{centenas de milhares de operadores}.
    \pause
    \item Isso quer dizer que aprender operadores preferidos é uma tarefa \alert{difícil}.
  \end{itemize}
  \pause
  \item Trabalho futuro pode explorar alternativas que permitam o treinamento com um \alert{número menor de amostras}.
\end{itemize}
\end{frame}


\begin{frame}[allowframebreaks]
\frametitle{Referências}
\printbibliography
\end{frame}

\end{document}
